{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sho6210/SecDev2023/blob/main/MLR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "C2uEt6ECeG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.lib.function_base import vectorize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from numpy.core.fromnumeric import size\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import tqdm\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import urllib.request\n",
        "import shutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2iu9jfOyXCG",
        "outputId": "182ec30b-9bfa-4e89-e924-3208bc63540f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "yNbpVXdG30by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "metric = 'cvssV3_attackVector'\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/SecDev2023/main/data/cve_2018-2020_complete_dataset.csv\", header=0)"
      ],
      "metadata": {
        "id": "2QCcZ0vZ35Hb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a data set"
      ],
      "metadata": {
        "id": "WSBbUp9PiJnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataSetMake(metric):\n",
        "  X = pd.DataFrame(df[['Description']])\n",
        "  y = pd.DataFrame(df[[metric]])\n",
        "  train_sentence, test_sentence, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n",
        "\n",
        "  # Display data distribution.\n",
        "  print(\"----------y_train:\", y_train.value_counts())\n",
        "  print(\"----------y_test:\", y_test.value_counts())\n",
        "\n",
        "  return train_sentence, test_sentence, y_train, y_test\n"
      ],
      "metadata": {
        "id": "nmsK4EY-ZjTk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (train)"
      ],
      "metadata": {
        "id": "YfYxevRwfneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_train(train_sentence):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer\n",
        "  vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "  X_train = vectorizer.fit_transform(train_sentence['Description'].values)\n",
        "  print('dimensions:', X_train.shape)\n",
        "  \n",
        "  return X_train, vectorizer"
      ],
      "metadata": {
        "id": "UFh_yTKG_L3d"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (train)"
      ],
      "metadata": {
        "id": "OhGKDuML0g93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_train(X_train, y_train): \n",
        "  # Create a classification model for MLR using vectorized features\n",
        "  lr = LogisticRegression(C=0.1, random_state=0, n_jobs=-1)\n",
        "  lr.fit(X_train, y_train)\n",
        "\n",
        "  return lr\n",
        "\n"
      ],
      "metadata": {
        "id": "A-Y15tpr_9jv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (test)"
      ],
      "metadata": {
        "id": "A1MAf62J0tPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_test(test_sentence, vectorizer):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer.\n",
        "  X_test = vectorizer.transform(test_sentence['Description'].values)\n",
        "  \n",
        "  return X_test"
      ],
      "metadata": {
        "id": "JVv9EtnWlZrm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (test)"
      ],
      "metadata": {
        "id": "2rxS6KVU0vh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_test(metric, X_test, y_test, lr):\n",
        "  # Test data to confirm accuracy.\n",
        "  y_pred = lr.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Branching when creating a table.\n",
        "  if metric == 'cvssV3_attackVector':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted A', 'Predicted L', 'Predicted N', 'Predicted P'], index=['Actual A', 'Actual L', 'Actual N', 'Actual P'])\n",
        "  elif metric == 'cvssV3_attackComplexity':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L'], index=['Actual H', 'Actual L'])\n",
        "  elif metric == 'cvssV3_privilegesRequired':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L', 'Predicted N'], index=['Actual H', 'Actual L', 'Actual N'])\n",
        "  elif metric == 'cvssV3_userInteraction':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted R'], index=['Actual N', 'Actual R'])\n",
        "  elif metric == 'cvssV3_scope':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted C', 'Predicted U'], index=['Actual C', 'Actual U'])\n",
        "  else:\n",
        "    table = pd.DataFrame(cm, columns=['Predicted H', 'Predicted L', 'Predicted N'], index=['Actual H', 'Actual L', 'Actual N'])\n",
        "\n",
        "  # Accuracy\n",
        "  print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(classification_report(y_test, y_pred, digits=4))\n",
        "  print(table)\n",
        "  print('-'*70)\n",
        "\n",
        "  # Returns a list containing the prediction results and a data frame for testing.\n",
        "  return y_pred\n",
        "\n"
      ],
      "metadata": {
        "id": "65tQ7Pvnmg76"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraction of input tokens"
      ],
      "metadata": {
        "id": "5KxnnzIa-LO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ExtractionTokens(vectorizer, lr):\n",
        "  # Get the name of the feature (word).\n",
        "  feature_names = vectorizer.get_feature_names_out() \n",
        "  \n",
        "  # Binary time.\n",
        "  if lr.coef_.shape[0] == 1:\n",
        "    coef = lr.coef_[0] \n",
        "\n",
        "   # Extraction of positively and negatively impacted words.\n",
        "    positive_words = [feature_names[i] for i in coef.argsort()[-10:]]\n",
        "    negative_words = [feature_names[i] for i in coef.argsort()[:10]]\n",
        "\n",
        "    print('Positive words:', positive_words)\n",
        "    print('Negative words:', negative_words)\n",
        "\n",
        "\n",
        "  # At three values or more.\n",
        "  if lr.coef_.shape[0] != 1:\n",
        "\n",
        "    # 分類区分ごとのポジティブとネガティブな単語の抽出\n",
        "    coef_matrix = lr.coef_\n",
        "    for i, class_name in enumerate(lr.classes_):\n",
        "      coef = coef_matrix[i]\n",
        "      positive_words = [feature_names[j] for j in coef.argsort()[-10:]]\n",
        "      negative_words = [feature_names[j] for j in coef.argsort()[:10]]\n",
        "      \n",
        "      print(\"Class:\", class_name)\n",
        "      print(\"Positive words:\", positive_words)\n",
        "      print(\"Negative words:\", negative_words)\n",
        "    print('-' * 50)"
      ],
      "metadata": {
        "id": "LmArZLjA8psu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "dYF-OpMa03Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# metrics = ['cvssV3_attackVector','cvssV3_attackComplexity','cvssV3_privilegesRequired','cvssV3_userInteraction',\n",
        "#            'cvssV3_scope','cvssV3_confidentialityImpact','cvssV3_integrityImpact','cvssV3_availabilityImpact']\n",
        "\n",
        "metric = 'cvssV3_attackVector'\n",
        "train_sentence, test_sentence, y_train, y_test = DataSetMake(metric)\n",
        "\n",
        "X_train, vectorizer = NLP_train(train_sentence)\n",
        "lr = MLR_train(X_train, y_train)\n",
        "\n",
        "X_test = NLP_test(test_sentence, vectorizer)\n",
        "y_pred = MLR_test(metric, X_test, y_test, lr)\n",
        "\n",
        "ExtractionTokens(vectorizer, lr)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB6I7HqcofQ2",
        "outputId": "e36613b2-737f-49ba-e153-a652d3170cdd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------y_train: cvssV3_attackVector\n",
            "NETWORK                17045\n",
            "LOCAL                   5046\n",
            "ADJACENT_NETWORK         575\n",
            "PHYSICAL                 297\n",
            "dtype: int64\n",
            "----------y_test: cvssV3_attackVector\n",
            "NETWORK                17045\n",
            "LOCAL                   5047\n",
            "ADJACENT_NETWORK         575\n",
            "PHYSICAL                 296\n",
            "dtype: int64\n",
            "dimensions: (22963, 36446)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9033227365762313\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "ADJACENT_NETWORK     0.7989    0.4974    0.6131       575\n",
            "           LOCAL     0.8613    0.7741    0.8154      5047\n",
            "         NETWORK     0.9165    0.9643    0.9398     17045\n",
            "        PHYSICAL     0.8382    0.3851    0.5278       296\n",
            "\n",
            "        accuracy                         0.9033     22963\n",
            "       macro avg     0.8537    0.6552    0.7240     22963\n",
            "    weighted avg     0.9004    0.9033    0.8990     22963\n",
            "\n",
            "          Predicted A  Predicted L  Predicted N  Predicted P\n",
            "Actual A          286           30          256            3\n",
            "Actual L           16         3907         1114           10\n",
            "Actual N           54          546        16436            9\n",
            "Actual P            2           53          127          114\n",
            "----------------------------------------------------------------------\n",
            "Class: ADJACENT_NETWORK\n",
            "Positive words: ['authenticated', 'devices', 'segment', 'wireless', 'zte', 'network', 'hyper', 'bluetooth', 'netgear', 'adjacent']\n",
            "Negative words: ['file', 'function', 'users', 'php', 'successful', 'discovered', 'application', 'xss', '20', 'fixed']\n",
            "Class: LOCAL\n",
            "Positive words: ['30102', 'executes', 'hijacking', 'locally', 'artifex', 'ansible', 'crafted', 'logon', 'xpdf', 'local']\n",
            "Negative words: ['xss', 'unauthenticated', 'network', 'physical', 'usb', 'scripting', 'http', 'inclusion', 'devices', 'tcp']\n",
            "Class: NETWORK\n",
            "Positive words: ['http', 'token', 'gdi', 'edge', 'libxaac', 'inclusion', 'scripting', 'csrf', 'remote', 'xss']\n",
            "Negative words: ['local', 'adjacent', 'physical', 'netgear', 'logon', 'xpdf', 'executes', 'locally', 'ansible', 'bluetooth']\n",
            "Class: PHYSICAL\n",
            "Positive words: ['smartphones', 'locked', 'telium', 'opensc', 'card', 'proximate', 'physically', 'screen', 'usb', 'physical']\n",
            "Negative words: ['remote', 'authenticated', 'service', 'request', 'network', 'injection', 'server', 'directory', 'macos', 'stack']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJBg_1P0G4TV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}